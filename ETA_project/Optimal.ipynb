{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d5bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca7ea0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EARTH_RADIUS_KM = 6371.0088\n",
    "CSV_PATH = Path(\"Raw Data\") / \"Device_AB00030.csv\"\n",
    "TARGET_MMSI = 636012794\n",
    "FIRST_STAGE_EPS = 0.01  # radians; ~63 km\n",
    "FIRST_STAGE_MIN_SAMPLES = 10\n",
    "SECOND_STAGE_EPS_KM = 1.0  # merge harbour centers within 1 km\n",
    "SOG_THRESHOLD = 2.0  # knots; below this is considered \"slow\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a827cf",
   "metadata": {},
   "source": [
    "## Data Preprcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f61bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(csv_path: Path = CSV_PATH, target_mmsi: int = TARGET_MMSI) -> pd.DataFrame:\n",
    "    \"\"\"Load the raw AIS data and apply the filters specified in the spec.\"\"\"\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    df = df[df[\"MMSI\"] == target_mmsi].copy()\n",
    "\n",
    "    df[\"Lat\"] = pd.to_numeric(df[\"Lat\"], errors=\"coerce\")\n",
    "    df[\"Long\"] = pd.to_numeric(df[\"Long\"], errors=\"coerce\")\n",
    "    df[\"Sog\"] = pd.to_numeric(df[\"Sog\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Lat\", \"Long\", \"Sog\"])\n",
    "\n",
    "    df = df[df[\"Lat\"].between(-90.0, 90.0)]\n",
    "    df = df[df[\"Long\"].between(-180.0, 180.0)]\n",
    "\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"].astype(str), format=\"%Y%m%d%H%M%S\", errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Timestamp\"])\n",
    "\n",
    "    slow_df = df[df[\"Sog\"] < SOG_THRESHOLD].copy()\n",
    "    return slow_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1495523",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e755e5b",
   "metadata": {},
   "source": [
    "### haversine 將經緯度轉換成radius_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd31c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# haversine to radius km\n",
    "def _haversine_km(latitudes: Iterable[float], longitudes: Iterable[float], center_lat: float, center_lon: float) -> np.ndarray:\n",
    "    \"\"\"Vectorised haversine distance from points to a single center in kilometres.\"\"\"\n",
    "    latitudes = np.asarray(latitudes, dtype=float)\n",
    "    longitudes = np.asarray(longitudes, dtype=float)\n",
    "\n",
    "    lat_rad = np.radians(latitudes)\n",
    "    lon_rad = np.radians(longitudes)\n",
    "    center_lat_rad = np.radians(center_lat)\n",
    "    center_lon_rad = np.radians(center_lon)\n",
    "\n",
    "    delta_lat = lat_rad - center_lat_rad\n",
    "    delta_lon = lon_rad - center_lon_rad\n",
    "\n",
    "    sin_lat = np.sin(delta_lat / 2.0)\n",
    "    sin_lon = np.sin(delta_lon / 2.0)\n",
    "\n",
    "    a = sin_lat ** 2 + np.cos(center_lat_rad) * np.cos(lat_rad) * sin_lon ** 2\n",
    "    c = 2.0 * np.arcsin(np.sqrt(np.clip(a, 0.0, 1.0)))\n",
    "    return EARTH_RADIUS_KM * c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a4924",
   "metadata": {},
   "source": [
    "### haversine to radius radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13c6c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _haversine_rad_vector(points_rad: np.ndarray, center_rad: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Great-circle distance from multiple points to a single center, expressed in radians.\"\"\"\n",
    "    delta_lat = points_rad[:, 0] - center_rad[0]\n",
    "    delta_lon = points_rad[:, 1] - center_rad[1]\n",
    "\n",
    "    sin_lat = np.sin(delta_lat / 2.0)\n",
    "    sin_lon = np.sin(delta_lon / 2.0)\n",
    "\n",
    "    a = sin_lat ** 2 + np.cos(center_rad[0]) * np.cos(points_rad[:, 0]) * sin_lon ** 2\n",
    "    return 2.0 * np.arcsin(np.sqrt(np.clip(a, 0.0, 1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c8d50",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa3ed195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dbscan_haversine(coords_rad: np.ndarray, eps: float, min_samples: int) -> np.ndarray:\n",
    "    \"\"\"Lightweight DBSCAN implementation tailored for haversine distances.\"\"\"\n",
    "    n_samples = len(coords_rad)\n",
    "    if n_samples == 0:\n",
    "        return np.empty((0,), dtype=int)\n",
    "\n",
    "    coords_rad = np.asarray(coords_rad, dtype=float)\n",
    "    labels = np.full(n_samples, -1, dtype=int)\n",
    "    visited = np.zeros(n_samples, dtype=bool)\n",
    "\n",
    "    eps_deg = max(np.degrees(eps), 1e-6)\n",
    "    lat_deg = np.degrees(coords_rad[:, 0])\n",
    "    lon_deg = np.degrees(coords_rad[:, 1])\n",
    "\n",
    "    grid: dict[tuple[int, int], list[int]] = {}\n",
    "    for idx in range(n_samples):\n",
    "        cell = (int(np.floor(lat_deg[idx] / eps_deg)), int(np.floor(lon_deg[idx] / eps_deg)))\n",
    "        grid.setdefault(cell, []).append(idx)\n",
    "\n",
    "    def region_query(point_idx: int) -> np.ndarray:\n",
    "        base_cell = (int(np.floor(lat_deg[point_idx] / eps_deg)), int(np.floor(lon_deg[point_idx] / eps_deg)))\n",
    "        candidate_indices: list[int] = []\n",
    "        for d_lat in (-1, 0, 1):\n",
    "            for d_lon in (-1, 0, 1):\n",
    "                candidate_indices.extend(grid.get((base_cell[0] + d_lat, base_cell[1] + d_lon), []))\n",
    "        if not candidate_indices:\n",
    "            return np.empty((0,), dtype=int)\n",
    "        unique_candidates = np.unique(candidate_indices)\n",
    "        distances = _haversine_rad_vector(coords_rad[unique_candidates], coords_rad[point_idx])\n",
    "        return unique_candidates[distances <= eps]\n",
    "\n",
    "    cluster_id = -1\n",
    "    for point_idx in range(n_samples):\n",
    "        if visited[point_idx]:\n",
    "            continue\n",
    "\n",
    "        visited[point_idx] = True\n",
    "        neighbors = region_query(point_idx)\n",
    "        if neighbors.size < min_samples:\n",
    "            labels[point_idx] = -1\n",
    "            continue\n",
    "\n",
    "        cluster_id += 1\n",
    "        labels[point_idx] = cluster_id\n",
    "        neighbor_set = set(map(int, neighbors.tolist()))\n",
    "        neighbor_set.discard(point_idx)\n",
    "        queue = deque(neighbor_set)\n",
    "\n",
    "        while queue:\n",
    "            current_point = queue.pop()\n",
    "            if not visited[current_point]:\n",
    "                visited[current_point] = True\n",
    "                current_neighbors = region_query(current_point)\n",
    "                if current_neighbors.size >= min_samples:\n",
    "                    for neighbor_idx in map(int, current_neighbors.tolist()):\n",
    "                        if neighbor_idx not in neighbor_set:\n",
    "                            neighbor_set.add(neighbor_idx)\n",
    "                            queue.append(neighbor_idx)\n",
    "            labels[current_point] = cluster_id\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6beb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(csv_path: Path = CSV_PATH, target_mmsi: int = TARGET_MMSI) -> pd.DataFrame:\n",
    "    \"\"\"Load the raw AIS data and apply the filters specified in the spec.\"\"\"\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    df = df[df[\"MMSI\"] == target_mmsi].copy()\n",
    "\n",
    "    df[\"Lat\"] = pd.to_numeric(df[\"Lat\"], errors=\"coerce\")\n",
    "    df[\"Long\"] = pd.to_numeric(df[\"Long\"], errors=\"coerce\")\n",
    "    df[\"Sog\"] = pd.to_numeric(df[\"Sog\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Lat\", \"Long\", \"Sog\"])\n",
    "\n",
    "    df = df[df[\"Lat\"].between(-90.0, 90.0)]\n",
    "    df = df[df[\"Long\"].between(-180.0, 180.0)]\n",
    "\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"].astype(str), format=\"%Y%m%d%H%M%S\", errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Timestamp\"])\n",
    "\n",
    "    slow_df = df[df[\"Sog\"] < 0.2].copy()\n",
    "    return slow_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd4cc9",
   "metadata": {},
   "source": [
    "## 2 DBSCAN Algrorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2e63aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _first_stage_clusters(slow_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Run the first DBSCAN over low-speed points and return cluster summaries and memberships.\"\"\"\n",
    "    if slow_df.empty:\n",
    "        empty_cols = [\"cluster_id\", \"center_lat\", \"center_lon\", \"radius_km\"]\n",
    "        return pd.DataFrame(columns=empty_cols), slow_df.assign(cluster_id=pd.Series(dtype=int))\n",
    "\n",
    "    coords_rad = np.radians(slow_df[[\"Lat\", \"Long\"]].to_numpy())\n",
    "    labels = _dbscan_haversine(coords_rad, eps=FIRST_STAGE_EPS, min_samples=FIRST_STAGE_MIN_SAMPLES)\n",
    "\n",
    "    slow_df = slow_df.copy()\n",
    "    slow_df[\"cluster_id\"] = labels\n",
    "    member_df = slow_df[slow_df[\"cluster_id\"] >= 0].copy()\n",
    "\n",
    "    if member_df.empty:\n",
    "        empty_cols = [\"cluster_id\", \"center_lat\", \"center_lon\", \"radius_km\"]\n",
    "        return pd.DataFrame(columns=empty_cols), member_df\n",
    "\n",
    "    summaries = []\n",
    "    for cluster_id, cluster_points in member_df.groupby(\"cluster_id\"):\n",
    "        center_lat = cluster_points[\"Lat\"].mean()\n",
    "        center_lon = cluster_points[\"Long\"].mean()\n",
    "        distances = _haversine_km(cluster_points[\"Lat\"].to_numpy(), cluster_points[\"Long\"].to_numpy(), center_lat, center_lon)\n",
    "        radius_km = float(np.quantile(distances, 0.95) * 1.2) if len(distances) else 0.0\n",
    "        summaries.append({\n",
    "            \"cluster_id\": cluster_id,\n",
    "            \"center_lat\": center_lat,\n",
    "            \"center_lon\": center_lon,\n",
    "            \"radius_km\": radius_km,\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summaries)\n",
    "    return summary_df, member_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b70d5f",
   "metadata": {},
   "source": [
    "### merge_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "167f4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_clusters(summary_df: pd.DataFrame, member_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge nearby harbour clusters using a secondary DBSCAN over the centroids.\"\"\"\n",
    "    if summary_df.empty:\n",
    "        return pd.DataFrame(columns=[\"port_id\", \"center_lat\", \"center_lon\", \"radius_km\", \"num_points\"])\n",
    "\n",
    "    centers_rad = np.radians(summary_df[[\"center_lat\", \"center_lon\"]].to_numpy())\n",
    "    eps_rad = SECOND_STAGE_EPS_KM / EARTH_RADIUS_KM\n",
    "    merge_labels = _dbscan_haversine(centers_rad, eps=eps_rad, min_samples=1)\n",
    "\n",
    "    summary_df = summary_df.copy()\n",
    "    summary_df[\"merge_id\"] = merge_labels\n",
    "\n",
    "    merged_ports = []\n",
    "    for port_index, (merge_id, subset) in enumerate(summary_df.groupby(\"merge_id\")):\n",
    "        member_ids = subset[\"cluster_id\"].tolist()\n",
    "        merged_points = member_df[member_df[\"cluster_id\"].isin(member_ids)]\n",
    "\n",
    "        center_lat = merged_points[\"Lat\"].mean()\n",
    "        center_lon = merged_points[\"Long\"].mean()\n",
    "        distances = _haversine_km(\n",
    "            merged_points[\"Lat\"].to_numpy(),\n",
    "            merged_points[\"Long\"].to_numpy(),\n",
    "            center_lat, center_lon\n",
    "        )\n",
    "        radius_km = float(np.quantile(distances, 0.95) * 1.2) if len(distances) else 0.0\n",
    "\n",
    "        merged_ports.append({\n",
    "            \"port_id\": port_index,\n",
    "            \"center_lat\": center_lat,\n",
    "            \"center_lon\": center_lon,\n",
    "            \"radius_km\": radius_km,\n",
    "            \"num_points\": len(merged_points)   # 新增：該港口包含多少個點\n",
    "        })\n",
    "\n",
    "    merged_df = pd.DataFrame(merged_ports)\n",
    "    return merged_df.sort_values(\"port_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9aabb",
   "metadata": {},
   "source": [
    "## Detect Port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df8b05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ports(csv_path: Path = CSV_PATH, target_mmsi: int = TARGET_MMSI) -> pd.DataFrame:\n",
    "    \"\"\"High-level helper that runs the entire harbour-detection pipeline.\"\"\"\n",
    "    slow_df = load_and_preprocess(csv_path, target_mmsi)\n",
    "    summary_df, member_df = _first_stage_clusters(slow_df)\n",
    "    ports = _merge_clusters(summary_df, member_df)\n",
    "\n",
    "    # 將結果存到 port_info.csv\n",
    "    if not ports.empty:\n",
    "        ports.to_csv(\"port_info.csv\", index=False)\n",
    "    return ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9842d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Ports:\n",
      " port_id  center_lat  center_lon  radius_km  num_points\n",
      "       0   31.066710  122.818839  25.594699        2028\n",
      "       1   31.339199  121.652300   0.722596        1584\n",
      "       2   10.656415  103.493426   4.474448        4381\n",
      "       3   13.363524  100.711246  47.664840        4499\n",
      "       4   21.547077  108.680328  22.447665        1125\n",
      "       5   29.516380  122.700605   7.223549         839\n",
      "       6   29.935898  121.868849   0.644467        1958\n",
      "       7   22.646979  113.681702   0.025511         128\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ports = detect_ports()\n",
    "    if ports.empty:\n",
    "        print(\"No ports detected with the current parameters.\")\n",
    "    else:\n",
    "        print(\"Detected Ports:\")\n",
    "        print(ports.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef62afc",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2a495a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Ports:\n",
      " port_id  center_lat  center_lon  radius_km  num_points\n",
      "       0   31.066710  122.818839  25.594699        2028\n",
      "       1   31.339199  121.652300   0.722596        1584\n",
      "       2   10.656415  103.493426   4.474448        4381\n",
      "       3   13.363524  100.711246  47.664840        4499\n",
      "       4   21.547077  108.680328  22.447665        1125\n",
      "       5   29.516380  122.700605   7.223549         839\n",
      "       6   29.935898  121.868849   0.644467        1958\n",
      "       7   22.646979  113.681702   0.025511         128\n",
      "Map saved to ports_map.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "def visualize_ports(ports: pd.DataFrame, map_filename: str = \"ports_map.html\") -> None:\n",
    "    \"\"\"Visualize detected ports on a Folium map and save to HTML.\"\"\"\n",
    "    if ports.empty:\n",
    "        print(\"No ports to visualize.\")\n",
    "        return\n",
    "\n",
    "    # 以所有港口中心的平均值作為地圖中心\n",
    "    center_lat = ports[\"center_lat\"].mean()\n",
    "    center_lon = ports[\"center_lon\"].mean()\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=5, tiles=\"OpenStreetMap\")\n",
    "\n",
    "    for _, row in ports.iterrows():\n",
    "        # 畫圓形範圍\n",
    "        folium.Circle(\n",
    "            location=[row[\"center_lat\"], row[\"center_lon\"]],\n",
    "            radius=row[\"radius_km\"] * 1000,  # km -> m\n",
    "            color=\"blue\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.2,\n",
    "            popup=f\"Port {row['port_id']}<br>\"\n",
    "                  f\"Radius: {row['radius_km']:.2f} km<br>\"\n",
    "                  f\"Points: {row['num_points']}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "        # 畫中心點\n",
    "        folium.Marker(\n",
    "            location=[row[\"center_lat\"], row[\"center_lon\"]],\n",
    "            icon=folium.Icon(color=\"red\", icon=\"anchor\", prefix=\"fa\"),\n",
    "            popup=f\"Port {row['port_id']}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    m.save(map_filename)\n",
    "    print(f\"Map saved to {map_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ports = detect_ports()\n",
    "    if ports.empty:\n",
    "        print(\"No ports detected with the current parameters.\")\n",
    "    else:\n",
    "        print(\"Detected Ports:\")\n",
    "        print(ports.to_string(index=False))\n",
    "\n",
    "        # 存檔\n",
    "        ports.to_csv(\"port_info.csv\", index=False)\n",
    "\n",
    "        # 可視化\n",
    "        visualize_ports(ports, \"ports_map.html\")\n",
    "    \n",
    "\n",
    "import webbrowser\n",
    "\n",
    "webbrowser.open(\"ports_map.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95fa0002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved to ports_map.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "def visualize_ports(ports: pd.DataFrame, map_filename: str = \"ports_map.html\", show_inline: bool = True):\n",
    "    \"\"\"Visualize detected ports on a Folium map.\n",
    "    \n",
    "    Args:\n",
    "        ports: DataFrame containing port_id, center_lat, center_lon, radius_km, num_points.\n",
    "        map_filename: File path to save the HTML map.\n",
    "        show_inline: If True and running in Jupyter, show map inline.\n",
    "    \"\"\"\n",
    "    if ports.empty:\n",
    "        print(\"No ports to visualize.\")\n",
    "        return None\n",
    "\n",
    "    # 地圖中心點 = 港口中心的平均\n",
    "    center_lat = ports[\"center_lat\"].mean()\n",
    "    center_lon = ports[\"center_lon\"].mean()\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=6, tiles=\"OpenStreetMap\")\n",
    "\n",
    "    for _, row in ports.iterrows():\n",
    "        # 畫圓形範圍\n",
    "        folium.Circle(\n",
    "            location=[row[\"center_lat\"], row[\"center_lon\"]],\n",
    "            radius=row[\"radius_km\"] * 1000,  # km → m\n",
    "            color=\"blue\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.2,\n",
    "            popup=(f\"Port {row['port_id']}<br>\"\n",
    "                   f\"Radius: {row['radius_km']:.2f} km<br>\"\n",
    "                   f\"Points: {row['num_points']}\")\n",
    "        ).add_to(m)\n",
    "\n",
    "        # 畫中心點\n",
    "        folium.Marker(\n",
    "            location=[row[\"center_lat\"], row[\"center_lon\"]],\n",
    "            icon=folium.Icon(color=\"red\", icon=\"anchor\", prefix=\"fa\"),\n",
    "            popup=f\"Port {row['port_id']}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    # 存成 HTML\n",
    "    m.save(map_filename)\n",
    "    print(f\"Map saved to {map_filename}\")\n",
    "\n",
    "    # 如果在 Jupyter Notebook 中，直接顯示地圖\n",
    "    if show_inline:\n",
    "        return m\n",
    "    return None\n",
    "\n",
    "\n",
    "visualize_ports(ports, \"ports_map.html\")\n",
    "import webbrowser\n",
    "\n",
    "webbrowser.open(\"ports_map.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
